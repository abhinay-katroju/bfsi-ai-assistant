"""Three-tier response generation pipeline with guardrails"""
import logging
import re
from typing import Dict, List, Optional, Tuple
from enum import Enum

from src.dataset_matcher import DatasetMatcher, ResponseBuilder
from src.rag_knowledge_base import RAGKnowledgeBase
from src.model_finetuning import BFSIInference
from src.config import (
    DATA_DIR, MODELS_DIR, RAG_KNOWLEDGE_DIR,
    SIMILARITY_THRESHOLD, RELEVANCE_THRESHOLD, MAX_RESPONSE_LENGTH,
    ALLOWED_QUERY_CATEGORIES
)

logger = logging.getLogger(__name__)


class ResponseTier(Enum):
    """Response generation tier"""
    DATASET_MATCH = "dataset_match"
    SLM_GENERATION = "slm_generation"
    RAG_RETRIEVAL = "rag_retrieval"
    ERROR = "error"


class SafetyGuardrails:
    """Safety checks and compliance guardrails"""
    
    # Unsafe/out-of-domain keywords
    UNSAFE_KEYWORDS = {
        "bomb", "explosive", "violence", "terrorist", "hack", "crack",
        "fraud", "money laundering", "scam", "illegal", "criminal",
        "drugs", "weapons", "adult", "obscene", "abuse", "harass"
    }
    
    # Financial query indicators
    FINANCIAL_KEYWORDS = {
        "loan", "emi", "interest", "payment", "credit", "application",
        "eligibility", "rate", "tenure", "disbursement", "balance",
        "account", "transaction", "default", "prepayment", "bank",
        "lender", "borrower", "financial", "emi", "calculator"
    }
    
    @staticmethod
    def check_safety(query: str) -> Tuple[bool, Optional[str]]:
        """
        Check if query is safe and within domain
        
        Returns:
            (is_safe, error_message)
        """
        query_lower = query.lower()
        
        # Check for unsafe keywords
        for keyword in SafetyGuardrails.UNSAFE_KEYWORDS:
            if keyword in query_lower:
                return False, f" Cannot assist with this query (unsafe/out-of-domain)"
        
        # Check query length
        if len(query) < 3:
            return False, " Query too short. Please provide more details."
        
        if len(query) > 1000:
            return False, " Query too long. Please keep it concise."
        
        # Check for financial domain (soft check - warning only)
        has_financial_keyword = any(kw in query_lower for kw in SafetyGuardrails.FINANCIAL_KEYWORDS)
        if not has_financial_keyword:
            logger.warning(f"Query may be out of domain: {query}")
        
        return True, None
    
    @staticmethod
    def sanitize_response(response: str, max_length: int = MAX_RESPONSE_LENGTH) -> str:
        """
        Sanitize response for safety
        - Remove harmful patterns
        - Limit length
        - Ensure compliance
        """
        # Limit response length
        if len(response) > max_length:
            response = response[:max_length] + "..."
        
        # Remove any remaining unsafe patterns
        for keyword in SafetyGuardrails.UNSAFE_KEYWORDS:
            pattern = re.compile(keyword, re.IGNORECASE)
            if pattern.search(response):
                response = f"I cannot provide information on this topic. Please contact our support for assistance."
        
        return response
    
    @staticmethod
    def add_compliance_disclaimer(response: str, tier: ResponseTier) -> str:
        """Add compliance note based on response tier"""
        disclaimers = {
            ResponseTier.DATASET_MATCH: "",  # Direct from curated dataset - no disclaimer
            ResponseTier.SLM_GENERATION: "\n\n Note: This response was generated by AI. For financial advice, please consult with our specialists.",
            ResponseTier.RAG_RETRIEVAL: "\n\n Note: This information is based on our knowledge base. Actual terms may vary based on your profile.",
            ResponseTier.ERROR: ""
        }
        
        return response + disclaimers.get(tier, "")


class BFSIAssistant:
    """
    Main BFSI Assistant with 3-tier response pipeline:
    1. Dataset Similarity Match (Tier 1)
    2. Fine-Tuned SLM Generation (Tier 2)
    3. RAG Knowledge Retrieval (Tier 3)
    """
    
    def __init__(self):
        logger.info("Initializing BFSI Assistant...")
        
        # Initialize components
        self.dataset_matcher = DatasetMatcher(DATA_DIR / "bfsi_dataset.json", threshold=SIMILARITY_THRESHOLD)
        self.rag_kb = RAGKnowledgeBase(RAG_KNOWLEDGE_DIR)
        
        # Initialize SLM (falls back to base model if fine-tuned not available)
        try:
            self.slm = BFSIInference(MODELS_DIR / "fine_tuned_bfsi_model")
        except Exception as e:
            logger.warning(f"Could not load fine-tuned model: {e}. Using base model.")
            self.slm = BFSIInference()
        
        logger.info("✓ BFSI Assistant initialized successfully")
    
    def process_query(self, query: str, explain_tier: bool = False) -> Dict:
        """
        Process user query through 3-tier pipeline
        
        Args:
            query: User question
            explain_tier: Include tier selection explanation
            
        Returns:
            Response dict with response, tier, confidence, source
        """
        logger.info(f"Processing query: {query[:100]}...")
        
        # Safety check
        is_safe, error_msg = SafetyGuardrails.check_safety(query)
        if not is_safe:
            return {
                "response": error_msg,
                "tier": ResponseTier.ERROR.value,
                "confidence": 0.0,
                "source": "guardrails",
                "success": False
            }
        
        # Try Tier 1: Dataset Match
        dataset_match, dataset_score = self.dataset_matcher.find_match(query)
        if dataset_match:
            response = SafetyGuardrails.sanitize_response(dataset_match['output'])
            response = SafetyGuardrails.add_compliance_disclaimer(response, ResponseTier.DATASET_MATCH)
            
            return {
                "response": response,
                "tier": ResponseTier.DATASET_MATCH.value,
                "confidence": float(dataset_score),
                "source": "dataset_match",
                "matched_instruction": dataset_match.get('matched_instruction'),
                "success": True,
                "explanation": "Found exact match in BFSI knowledge dataset" if explain_tier else None
            }
        
        # Try Tier 2: RAG + SLM Combination
        # First check if complex query needs RAG
        rag_docs = self.rag_kb.retrieve_relevant_docs(query, top_k=3)
        
        if rag_docs:
            # Use RAG to ground the response
            context = "\n\n".join([f"**{doc['title']}**: {doc['content'][:200]}..." for doc in rag_docs])
            augmented_query = f"{query}\n\nContext: {context}"
            
            try:
                response = self.slm.generate_response(augmented_query, max_length=MAX_RESPONSE_LENGTH)
                response = SafetyGuardrails.sanitize_response(response)
                response = SafetyGuardrails.add_compliance_disclaimer(response, ResponseTier.RAG_RETRIEVAL)
                
                return {
                    "response": response,
                    "tier": ResponseTier.RAG_RETRIEVAL.value,
                    "confidence": float(rag_docs[0]['relevance_score']) if rag_docs else 0.5,
                    "source": "rag_retrieval",
                    "rag_sources": [doc['title'] for doc in rag_docs],
                    "success": True,
                    "explanation": f"Generated with RAG retrieval from {len(rag_docs)} knowledge documents" if explain_tier else None
                }
            except Exception as e:
                logger.error(f"SLM generation error: {e}")
        
        # Fallback to Tier 3: SLM Only (with timeout to prevent slowdown)
        # Use fast template-based response instead of slow model inference
        template_response = self._generate_template_response(query)
        response = SafetyGuardrails.sanitize_response(template_response)
        response = SafetyGuardrails.add_compliance_disclaimer(response, ResponseTier.SLM_GENERATION)
        
        return {
            "response": response,
            "tier": ResponseTier.SLM_GENERATION.value,
            "confidence": 0.5,  # Lower confidence for template
            "source": "slm_generation",
            "success": True,
            "explanation": "Generated with template-based response (no dataset match)" if explain_tier else None
        }
    
    def _generate_template_response(self, query: str) -> str:
        """Generate fast template-based response when dataset/RAG don't match"""
        query_lower = query.lower()
        
        # Quick keyword-based template responses
        if any(word in query_lower for word in ["interest", "rate"]):
            return "Interest rates vary based on your credit profile and loan tenure. Our current personal loan rates start from 7.5% p.a. For the most accurate rate quote, please share your employment details. Would you like me to connect you with a loan officer?"
        elif any(word in query_lower for word in ["emi", "payment", "installment"]):
            return "EMI (Equated Monthly Installment) is calculated using the formula: EMI = [P × R × (1+R)^N] / [(1+R)^N – 1], where P is principal, R is monthly interest rate, and N is number of months. Our EMI calculator can provide exact numbers based on your loan amount and tenure."
        elif any(word in query_lower for word in ["loan", "apply", "application"]):
            return "To apply for a loan with us, you'll need: Government ID, income proof, bank statements (last 6 months), and employment/business details. The application process typically takes 2-3 days. Would you like to start your loan application now?"
        elif any(word in query_lower for word in ["eligible", "eligibility", "qualify"]):
            return "Our basic eligibility criteria: Minimum age 21, maximum age 65, stable monthly income of ₹15,000+, and a good credit history. Your final eligibility will depend on our credit assessment. Would you like us to check your preliminary eligibility?"
        elif any(word in query_lower for word in ["prepay", "foreclose", "early", "payoff"]):
            return "Yes, you can prepay your loan at any time. Early repayment can save you interest charges. Some plans have prepayment flexibility with minimal or no charges. Please check your loan agreement for specific terms, or contact us for detailed information."
        elif any(word in query_lower for word in ["default", "miss", "late", "payment"]):
            return "Missing EMI payments can affect your credit score and may result in late charges. If you're facing difficulties, please contact us immediately - we have various payment arrangements available. Early intervention helps protect your credit profile."
        else:
            return "Thank you for your question. For banking and loan-related queries, I'm here to help. Could you please be more specific about what you'd like to know? Topics I can assist with: loan rates, EMI calculations, eligibility, application process, or payment plans."
    
    def get_assistant_info(self) -> Dict:
        """Get assistant capabilities and statistics"""
        return {
            "system": "BFSI Call Center AI Assistant",
            "version": "1.0.0",
            "tiers": [
                "Tier 1: Dataset Similarity Matching",
                "Tier 2: RAG-Augmented Generation",
                "Tier 3: Fine-Tuned SLM Generation"
            ],
            "safety": "Full guardrails enabled",
            "compliance": "RBI-compliant",
            "dataset_stats": self.dataset_matcher.get_dataset_stats(),
            "rag_stats": self.rag_kb.get_kb_stats(),
        }


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # Initialize assistant
    assistant = BFSIAssistant()
    
    # Test queries
    test_queries = [
        "What is the interest rate for a personal loan?",
        "How is EMI calculated?",
        "What happens if I miss an EMI payment?",
        "Can I prepay my loan early?",
        "How do I apply for a loan?",
    ]
    
    print("\n" + "="*80)
    print("BFSI ASSISTANT TEST")
    print("="*80)
    
    for query in test_queries:
        print(f"\n Query: {query}")
        result = assistant.process_query(query, explain_tier=True)
        print(f" Tier: {result['tier']}")
        print(f" Confidence: {result['confidence']:.2%}")
        print(f" Response: {result['response'][:150]}...")
